# PyTorch Factorization Machine

## âœ¨ ä¸»è¦åŠŸèƒ½

- **PyTorch å¯¦ç¾**ï¼šå®Œå…¨åŸºæ–¼ PyTorchï¼Œæ˜“æ–¼æ•´åˆåˆ°ç¾æœ‰çš„ç¥ç¶“ç¶²çµ¡æ¶æ§‹ä¸­ã€‚

- **å¯è‡ªè¨‚çš„å› å­ç¶­åº¦**ï¼šå¯ä»¥è¼•é¬†è¨­å®šäºŒæ¬¡é …äº¤äº’çš„å› å­ç¶­åº¦ï¼ˆfactorization_sizeï¼‰ã€‚

- **éˆæ´»çš„æ¿€æ´»å‡½æ•¸**ï¼šæ”¯æŒ identityï¼ˆç„¡æ¿€æ´»ï¼‰ã€sigmoid å’Œ tanh ä½œç‚ºè¼¸å‡ºå±¤çš„æ¿€æ´»å‡½æ•¸ã€‚

- **åƒæ•¸æå–**ï¼šæä¾› get_bhQ æ–¹æ³•ï¼Œæ–¹ä¾¿åœ°å°‡å­¸ç¿’åˆ°çš„æ¨¡å‹åƒæ•¸ï¼ˆbias, h, Vï¼‰è½‰æ›ç‚ºæ¨™æº–äºŒæ¬¡å¤šé …å¼å½¢å¼çš„åƒæ•¸ï¼ˆbias, h, Qï¼‰ï¼Œä¾¿æ–¼æ¨¡å‹åˆ†æå’Œè§£é‡‹ã€‚


## âš™ï¸ ç’°å¢ƒè¦æ±‚

æ‚¨éœ€è¦å®‰è£ä»¥ä¸‹ Python å¥—ä»¶æ‰èƒ½é‹è¡Œæ­¤ç¨‹å¼ç¢¼ï¼š

- **PyTorch**

- **NumPy**

## ğŸš€ å¦‚ä½•ä½¿ç”¨

ä»¥ä¸‹æ˜¯ä¸€å€‹å®Œæ•´çš„ä½¿ç”¨ç¯„ä¾‹ï¼Œå±•ç¤ºäº†å¦‚ä½•åˆå§‹åŒ–æ¨¡å‹ã€é€²è¡Œå‰å‘å‚³æ’­ï¼Œä»¥åŠå¦‚ä½•å°‡å…¶ç”¨æ–¼ä¸€å€‹ç°¡å–®çš„è¨“ç·´è¿´åœˆã€‚

```python
import os
import time
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import dimod
from factorization_machine import FactorizationMachine
from torch.utils.data import TensorDataset, DataLoader

# --- è¨­å®šè¨“ç·´åƒæ•¸ ---
DATASET_SIZE = 10_000
TEST_NUM = 50_000
RANDOM_SEED = 42
VAR_NUM = 32
K = VAR_NUM
NUM_EPOCH = 5_000
LEARNING_RATE = 1e-3
BATCH_SIZE = 512

# --- 1. ç”¢ç”Ÿ BQM ---
print("1. Generating BQM...")
def custom_bias_generator(var_num):
    return np.random.uniform(-1, 1, var_num)
bqm = dimod.generators.gnm_random_bqm(
          variables=VAR_NUM,
          num_interactions=VAR_NUM*(VAR_NUM-1)/2,
          vartype=dimod.BINARY,
          bias_generator=custom_bias_generator
      )
print("   BQM generated.")

# --- 2. ç”¢ç”Ÿè¨“ç·´å’Œæ¸¬è©¦è³‡æ–™é›† ---
print("2. Generating training and testing datasets...")
xs_train = np.random.randint(0, 2, (DATASET_SIZE, VAR_NUM), dtype=np.int8)
ys_train = np.array([bqm.energy(x) for x in xs_train], dtype=np.float64)

xs_test = np.random.randint(0, 2, (TEST_NUM, VAR_NUM), dtype=np.int8)
ys_test = np.array([bqm.energy(x) for x in xs_test], dtype=np.float64)

os.makedirs("data", exist_ok=True)
np.save("data/xs_train.npy", xs_train)
np.save("data/ys_train.npy", ys_train)
np.save("data/xs_test.npy", xs_test)
np.save("data/ys_test.npy", ys_test)
print("   Datasets saved to 'data/' directory.")

# --- 3. ç”¢ç”Ÿä¸¦å„²å­˜åˆå§‹æ¬Šé‡ ---
print("3. Generating and saving initial model weights...")
model_py_init = FactorizationMachine(input_size=VAR_NUM, factorization_size=K)

# æå–æ¬Šé‡
initial_bias = model_py_init.bias.detach().numpy()
initial_h = model_py_init.h.detach().numpy()
initial_V = model_py_init.V.detach().numpy()

os.makedirs("data", exist_ok=True)
np.save("data/initial_bias.npy", initial_bias)
np.save("data/initial_h.npy", initial_h)
np.save("data/initial_V.npy", initial_V)
print("   Initial weights saved.")
print("\nData generation complete.")

# æå–æ¬Šé‡
initial_bias = model_py_init.bias.detach().numpy()
initial_h = model_py_init.h.detach().numpy()
initial_V = model_py_init.V.detach().numpy()

os.makedirs("data", exist_ok=True)
np.save("data/initial_bias.npy", initial_bias)
np.save("data/initial_h.npy", initial_h)
np.save("data/initial_V.npy", initial_V)
print("   Initial weights saved.")
print("\nData generation complete.")

# --- 4. è®€å–æ•¸æ“šå’Œåˆå§‹æ¬Šé‡ ---
print("1. Loading data and initial weights for PyTorch...")
xs_train = np.load("data/xs_train.npy")
ys_train = np.load("data/ys_train.npy")
xs_test = np.load("data/xs_test.npy")
ys_test = np.load("data/ys_test.npy")

initial_bias = np.load("data/initial_bias.npy")
initial_h = np.load("data/initial_h.npy")
initial_V = np.load("data/initial_V.npy")

# --- 5. åˆå§‹åŒ–æ¨¡å‹ä¸¦è¨­å®šæ¬Šé‡ ---
print("2. Initializing PyTorch model with pre-defined weights...")
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"   Using device: {device}")

model_py = FactorizationMachine(input_size=VAR_NUM, factorization_size=K, act="identity")

with torch.no_grad():
    model_py.bias.copy_(torch.from_numpy(initial_bias))
    model_py.h.copy_(torch.from_numpy(initial_h))
    model_py.V.copy_(torch.from_numpy(initial_V))
model_py.to(device)

# --- 6. è¨“ç·´æ¨¡å‹ ---
print("3. Starting PyTorch training on GPU...")
x_tensor = torch.from_numpy(xs_train).float()
y_tensor = torch.from_numpy(ys_train).float()
train_dataset = TensorDataset(x_tensor, y_tensor)
train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)

# å®šç¾©æå¤±å‡½æ•¸å’Œå„ªåŒ–å™¨
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model_py.parameters(), lr=LEARNING_RATE)

start_time = time.time()
model_py.train() # è¨­ç½®ç‚ºè¨“ç·´æ¨¡å¼
for epoch in range(NUM_EPOCH):
    total_loss = 0
    for i, (inputs, labels) in enumerate(train_loader):
        inputs, labels = inputs.to(device), labels.to(device)

        # å‰å‘å‚³æ’­
        outputs = model_py(inputs)
        loss = criterion(outputs.squeeze(), labels) # ä½¿ç”¨ squeeze() ä¾†åŒ¹é…ç¶­åº¦

        # åå‘å‚³æ’­å’Œå„ªåŒ–
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()

    if (epoch + 1) % 100 == 0:
        print(f'Epoch [{epoch+1}/{NUM_EPOCH}], Loss: {total_loss / len(train_loader):.4f}')

end_time = time.time()
print(f"   Training finished in {end_time - start_time:.2f} seconds.")

# --- 7. ä½¿ç”¨é€™å€‹å®Œæ•´çš„å°ç¨±çŸ©é™£ä¾†ç¹ªåœ–
print("4. Extracting BQM from the trained PyTorch model and predicting...")
model_py.eval() # è¨­ç½®ç‚ºè©•ä¼°æ¨¡å¼
model_py.cpu()  # å°‡æ¨¡å‹ç§»å› CPU ä»¥ä¾¿æ“ä½œ NumPy å’Œ dimod

b, h, Q_matrix_triu = model_py.get_bhQ()
V_numpy = model_py.V.detach().numpy()
Q_symmetric = V_numpy.T @ V_numpy
np.fill_diagonal(Q_symmetric, 0) # å°è§’ç·šå…ƒç´ ç‚º0

fig, ax = plt.subplots(figsize=(10, 8))
im = ax.imshow(Q_symmetric, cmap='coolwarm', interpolation='nearest')
cbar = fig.colorbar(im, ax=ax)
cbar.set_label('Interaction Strength')
ax.set_title("Final Symmetric Q Matrix from Trained PyTorch Model")
ax.set_xlabel("Variable Index")
ax.set_ylabel("Variable Index")

os.makedirs("results", exist_ok=True)
plt.savefig("results/Q_matrix_pytorch.png")
print("   Q matrix plot saved to results/Q_matrix_pytorch.png")

Q_dict = {(i, j): Q_matrix_triu[i, j] for i, j in zip(*np.where(Q_matrix_triu != 0))}
bqm_pred_pt = dimod.BinaryQuadraticModel(h, Q_dict, b, dimod.BINARY)
ys_pred_pytorch = np.array([bqm_pred_pt.energy(x) for x in xs_test], dtype=np.float64)

# --- 8. å„²å­˜çµæœ ---
print("5. Saving PyTorch results...")
np.save("results/ys_pred_pytorch.npy", ys_pred_pytorch)
print("\nPyTorch script finished.")

# --- 9. è®€å–æ‰€æœ‰çµæœ ---
ys_test = np.load("data/ys_test.npy")
ys_pred_pytorch = np.load("results/ys_pred_pytorch.npy")

# --- 10. ç¹ªè£½èƒ½é‡é æ¸¬åœ– ---
sorted_indices = np.argsort(ys_test)
ys_sorted = ys_test[sorted_indices]
ys_pred_pt_sorted = ys_pred_pytorch[sorted_indices]

plt.figure(figsize=(12, 7))
plt.plot(ys_sorted, color="blue", label="True Energy", linewidth=4, alpha=0.8)
plt.plot(ys_pred_pt_sorted, color="red", label="Predicted Energy (Mxnet)", linestyle='-')
plt.title("Comparison of True and Mxnet Predicted Energies", fontsize=16)
plt.xlabel("Sorted Sample Index", fontsize=16)
plt.ylabel("Energy", fontsize=16)
plt.legend(fontsize=16)
plt.grid(True)
plt.savefig("py_energy_comparison.png")
print("'energy_comparison.png' saved.")
# é¡¯ç¤ºåœ–è¡¨
plt.show()

